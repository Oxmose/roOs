[1mdiff --git a/.vscode/settings.json b/.vscode/settings.json[m
[1mindex 06dc2b6..0ad561f 100644[m
[1m--- a/.vscode/settings.json[m
[1m+++ b/.vscode/settings.json[m
[36m@@ -27,6 +27,7 @@[m
         "ioapic.h": "c",[m
         "*.c_no": "c",[m
         "tracing.h": "c",[m
[31m-        "x86memory.h": "c"[m
[32m+[m[32m        "x86memory.h": "c",[m
[32m+[m[32m        "x86cpu.h": "c"[m
     }[m
 }[m
\ No newline at end of file[m
[1mdiff --git a/Source/Config/arch/x86_64/Artifacts/dependencies.mk b/Source/Config/arch/x86_64/Artifacts/dependencies.mk[m
[1mindex b6b9f50..77d44e0 100644[m
[1m--- a/Source/Config/arch/x86_64/Artifacts/dependencies.mk[m
[1m+++ b/Source/Config/arch/x86_64/Artifacts/dependencies.mk[m
[36m@@ -13,6 +13,7 @@[m [mDEP_LIBS += -ltrace[m
 DEP_LIBS += -ltime[m
 DEP_LIBS += -llibc[m
 DEP_LIBS += -luser[m
[32m+[m[32mDEP_LIBS += -lsync[m
 DEP_LIBS += --whole-archive -lrawdtb[m
 ifeq ($(TESTS), TRUE)[m
 DEP_LIBS += --end-group[m
[36m@@ -24,6 +25,7 @@[m [mDEP_MODULES += -L../libs/bin[m
 DEP_MODULES += -L../core/bin[m
 DEP_MODULES += -L../time/bin[m
 DEP_MODULES += -L../user/bin[m
[32m+[m[32mDEP_MODULES += -L../sync/bin[m
 DEP_MODULES += -L../ARTIFACTS[m
 ifeq ($(TESTS), TRUE)[m
 DEP_MODULES += -L../test_framework/bin[m
[1mdiff --git a/Source/Config/arch/x86_i386/Artifacts/dependencies.mk b/Source/Config/arch/x86_i386/Artifacts/dependencies.mk[m
[1mindex b6b9f50..77d44e0 100755[m
[1m--- a/Source/Config/arch/x86_i386/Artifacts/dependencies.mk[m
[1m+++ b/Source/Config/arch/x86_i386/Artifacts/dependencies.mk[m
[36m@@ -13,6 +13,7 @@[m [mDEP_LIBS += -ltrace[m
 DEP_LIBS += -ltime[m
 DEP_LIBS += -llibc[m
 DEP_LIBS += -luser[m
[32m+[m[32mDEP_LIBS += -lsync[m
 DEP_LIBS += --whole-archive -lrawdtb[m
 ifeq ($(TESTS), TRUE)[m
 DEP_LIBS += --end-group[m
[36m@@ -24,6 +25,7 @@[m [mDEP_MODULES += -L../libs/bin[m
 DEP_MODULES += -L../core/bin[m
 DEP_MODULES += -L../time/bin[m
 DEP_MODULES += -L../user/bin[m
[32m+[m[32mDEP_MODULES += -L../sync/bin[m
 DEP_MODULES += -L../ARTIFACTS[m
 ifeq ($(TESTS), TRUE)[m
 DEP_MODULES += -L../test_framework/bin[m
[1mdiff --git a/Source/Kernel/arch/bsp/x86/dependencies.mk b/Source/Kernel/arch/bsp/x86/dependencies.mk[m
[1mindex fde2cfe..259c7f0 100755[m
[1m--- a/Source/Kernel/arch/bsp/x86/dependencies.mk[m
[1m+++ b/Source/Kernel/arch/bsp/x86/dependencies.mk[m
[36m@@ -5,6 +5,7 @@[m [mDEP_INCLUDES += -I ../../../core/includes[m
 DEP_INCLUDES += -I ../../../libs/libtrace/includes[m
 DEP_INCLUDES += -I ../../../test_framework/includes[m
 DEP_INCLUDES += -I ../../../time/includes[m
[32m+[m[32mDEP_INCLUDES += -I ../../../sync/includes[m
 DEP_INCLUDES += -I ../../cpu/includes[m
 DEP_INCLUDES += -I ../../../user/includes[m
 [m
[1mdiff --git a/Source/Kernel/arch/bsp/x86/src/kickstart.c b/Source/Kernel/arch/bsp/x86/src/kickstart.c[m
[1mindex 2b96e7e..6be16aa 100755[m
[1m--- a/Source/Kernel/arch/bsp/x86/src/kickstart.c[m
[1m+++ b/Source/Kernel/arch/bsp/x86/src/kickstart.c[m
[36m@@ -27,6 +27,7 @@[m
 #include <uart.h>          /* UART driver */[m
 #include <panic.h>         /* Kernel Panic */[m
 #include <kheap.h>         /* Kernel heap */[m
[32m+[m[32m#include <futex.h>         /* Futex library */[m[41m[m
 #include <memory.h>        /* Memory manager */[m
 #include <devtree.h>       /* Device tree manager */[m
 #include <userinit.h>      /* User initialization */[m
[36m@@ -131,7 +132,6 @@[m [mvoid kickstart(void)[m
 #endif[m
 [m
     KERNEL_INFO("UTK Kickstart\n");[m
[31m-[m
     /* Initialize the scheduler */[m
 [m
     /* Validate architecture */[m
[36m@@ -154,10 +154,6 @@[m [mvoid kickstart(void)[m
     exceptionInit();[m
     KERNEL_SUCCESS("Exception manager initialized\n");[m
 [m
[31m-#if TEST_INTERRUPT_ENABLED[m
[31m-    TEST_FRAMEWORK_END();[m
[31m-#endif[m
[31m-[m
     /* Init FDT */[m
     fdtInit((uintptr_t)&_KERNEL_DEV_TREE_BASE);[m
     KERNEL_SUCCESS("FDT initialized\n");[m
[36m@@ -166,11 +162,17 @@[m [mvoid kickstart(void)[m
     memoryMgrInit();[m
     KERNEL_SUCCESS("Memory manager initialized\n");[m
 [m
[31m-[m
     /* Init the scheduler */[m
     schedInit();[m
     KERNEL_SUCCESS("Scheduler initialized\n");[m
 [m
[32m+[m[32m    TEST_POINT_FUNCTION_CALL(interrupt_test, TEST_INTERRUPT_ENABLED);[m[41m[m
[32m+[m[32m    TEST_POINT_FUNCTION_CALL(exception_test, TEST_EXCEPTION_ENABLED);[m[41m[m
[32m+[m[41m[m
[32m+[m[32m    /* Init the futex library */[m[41m[m
[32m+[m[32m    futexLibInit();[m[41m[m
[32m+[m[32m    KERNEL_SUCCESS("Futex library initialized\n");[m[41m[m
[32m+[m[41m[m
     /* Init device manager */[m
     driverManagerInit();[m
     KERNEL_SUCCESS("Drivers initialized\n");[m
[36m@@ -181,36 +183,27 @@[m [mvoid kickstart(void)[m
      */[m
     coreMgtInit();[m
 [m
[32m+[m[32m#ifndef _TESTING_FRAMEWORK_ENABLED[m[41m[m
     /* Initialize the user functions */[m
     userInit();[m
     KERNEL_SUCCESS("User initialization done\n");[m
[32m+[m[32m#endif[m[41m[m
 [m
[31m-    TEST_POINT_FUNCTION_CALL(queue_test, TEST_OS_QUEUE_ENABLED);[m
     TEST_POINT_FUNCTION_CALL(kqueue_test, TEST_OS_KQUEUE_ENABLED);[m
[32m+[m[32m    TEST_POINT_FUNCTION_CALL(queue_test, TEST_OS_QUEUE_ENABLED);[m[41m[m
     TEST_POINT_FUNCTION_CALL(vector_test, TEST_OS_VECTOR_ENABLED);[m
     TEST_POINT_FUNCTION_CALL(uhashtable_test, TEST_OS_UHASHTABLE_ENABLED);[m
[31m-[m
[31m-#if TEST_KHEAP_ENABLED[m
[31m-    TEST_FRAMEWORK_END();[m
[31m-#endif[m
[31m-[m
[31m-    TEST_POINT_ASSERT_RCODE(TEST_KICKSTART_END_ID,[m
[31m-                            TRUE,[m
[31m-                            OS_NO_ERR,[m
[31m-                            OS_NO_ERR,[m
[31m-                            TEST_KICKSTART_ENABLED);[m
[31m-[m
[31m-#if !TEST_PANIC_ENABLED[m
[31m-    TEST_FRAMEWORK_END();[m
[32m+[m[32m#if TEST_PANIC_ENABLED[m[41m[m
[32m+[m[32m    PANIC(OS_NO_ERR, "PANIC TEST", "Test PANIC", TRUE);[m[41m[m
 #endif[m
 [m
     KERNEL_TRACE_EVENT(TRACE_KICKSTART_ENABLED, TRACE_KICKSTART_EXIT, 0);[m
 [m
[31m-    schedSchedule();[m
[32m+[m[32m    /* Call first schedule */[m[41m[m
[32m+[m[32m    schedScheduleNoInt();[m[41m[m
 [m
     /* Once the scheduler is started, we should never come back here. */[m
     KICKSTART_ASSERT(FALSE, "Kickstart Returned", OS_ERR_UNAUTHORIZED_ACTION);[m
 }[m
[31m-#undef MODULE_NAME[m
 [m
 /************************************ EOF *************************************/[m
\ No newline at end of file[m
[1mdiff --git a/Source/Kernel/arch/bsp/x86/src/lapic.c b/Source/Kernel/arch/bsp/x86/src/lapic.c[m
[1mindex 5e0f618..e812b46 100644[m
[1m--- a/Source/Kernel/arch/bsp/x86/src/lapic.c[m
[1m+++ b/Source/Kernel/arch/bsp/x86/src/lapic.c[m
[36m@@ -537,8 +537,6 @@[m [mstatic void _lapicStartCpu(const uint8_t kLapicId)[m
                  "Starting CPU with LAPIC id %d",[m
                  kLapicId);[m
 [m
[31m-    KERNEL_CRITICAL_LOCK(sDrvCtrl.lock);[m
[31m-[m
     /* Send the INIT IPI */[m
     _lapicWrite(LAPIC_ICRHI, kLapicId << ICR_DESTINATION_SHIFT);[m
     _lapicWrite(LAPIC_ICRLO,[m
[36m@@ -591,8 +589,6 @@[m [mstatic void _lapicStartCpu(const uint8_t kLapicId)[m
         KERNEL_ERROR("Failed to startup CPU with LAPIC ID %d\n", kLapicId);[m
     }[m
 [m
[31m-    KERNEL_CRITICAL_UNLOCK(sDrvCtrl.lock);[m
[31m-[m
     KERNEL_TRACE_EVENT(TRACE_X86_LAPIC_ENABLED,[m
                        TRACE_X86_LAPIC_START_CPU_EXIT,[m
                        2,[m
[1mdiff --git a/Source/Kernel/arch/bsp/x86/src/lapic_timer.c b/Source/Kernel/arch/bsp/x86/src/lapic_timer.c[m
[1mindex cbdfded..360a62d 100644[m
[1m--- a/Source/Kernel/arch/bsp/x86/src/lapic_timer.c[m
[1m+++ b/Source/Kernel/arch/bsp/x86/src/lapic_timer.c[m
[36m@@ -132,9 +132,6 @@[m [mtypedef struct[m
 [m
     /** @brief Time base driver */[m
     const kernel_timer_t* kpBaseTimer;[m
[31m-[m
[31m-    /** @brief Driver's lock */[m
[31m-    kernel_spinlock_t lock[MAX_CPU_COUNT];[m
 } lapic_timer_ctrl_t;[m
 [m
 /*******************************************************************************[m
[36m@@ -394,10 +391,6 @@[m [mstatic OS_RETURN_E _lapicTimerAttach(const fdt_node_t* pkFdtNode)[m
     }[m
     spDrvCtrl = pDrvCtrl;[m
     memset(pDrvCtrl, 0, sizeof(lapic_timer_ctrl_t));[m
[31m-    for(propLen = 0; propLen < MAX_CPU_COUNT; ++propLen)[m
[31m-    {[m
[31m-        KERNEL_SPINLOCK_INIT(pDrvCtrl->lock[propLen]);[m
[31m-    }[m
 [m
     pTimerDrv = kmalloc(sizeof(kernel_timer_t));[m
     if(pTimerDrv == NULL)[m
[36m@@ -674,6 +667,7 @@[m [mstatic void _lapicTimerEnable(void* pDrvCtrl)[m
     lapic_timer_ctrl_t* pLAPICTimerCtrl;[m
     uint32_t            lapicInitCount;[m
     uint8_t             cpuId;[m
[32m+[m[32m    uint32_t            intState;[m
 [m
 [m
     pLAPICTimerCtrl = GET_CONTROLER(pDrvCtrl);[m
[36m@@ -685,7 +679,7 @@[m [mstatic void _lapicTimerEnable(void* pDrvCtrl)[m
                        pLAPICTimerCtrl->disabledNesting[cpuId]);[m
 [m
 [m
[31m-    KERNEL_CRITICAL_LOCK(pLAPICTimerCtrl->lock[cpuId]);[m
[32m+[m[32m    KERNEL_ENTER_CRITICAL_LOCAL(intState);[m
 [m
     if(pLAPICTimerCtrl->disabledNesting[cpuId] > 0)[m
     {[m
[36m@@ -717,7 +711,7 @@[m [mstatic void _lapicTimerEnable(void* pDrvCtrl)[m
                          LAPIC_TIMER_MODE_PERIODIC);[m
     }[m
 [m
[31m-    KERNEL_CRITICAL_UNLOCK(pLAPICTimerCtrl->lock[cpuId]);[m
[32m+[m[32m    KERNEL_EXIT_CRITICAL_LOCAL(intState);[m
 [m
     KERNEL_TRACE_EVENT(TRACE_X86_LAPIC_TIMER_ENABLED,[m
                        TRACE_X86_LAPIC_TIMER_ENABLE_EXIT,[m
[36m@@ -729,6 +723,7 @@[m [mstatic void _lapicTimerDisable(void* pDrvCtrl)[m
 {[m
     lapic_timer_ctrl_t* pLAPICTimerCtrl;[m
     uint8_t             cpuId;[m
[32m+[m[32m    uint32_t            intState;[m
 [m
     pLAPICTimerCtrl = GET_CONTROLER(pDrvCtrl);[m
 [m
[36m@@ -738,7 +733,7 @@[m [mstatic void _lapicTimerDisable(void* pDrvCtrl)[m
                        1,[m
                        pLAPICTimerCtrl->disabledNesting[cpuId]);[m
 [m
[31m-    KERNEL_CRITICAL_LOCK(pLAPICTimerCtrl->lock[cpuId]);[m
[32m+[m[32m    KERNEL_ENTER_CRITICAL_LOCAL(intState);[m
 [m
     if(pLAPICTimerCtrl->disabledNesting[cpuId] < UINT32_MAX)[m
     {[m
[36m@@ -755,7 +750,7 @@[m [mstatic void _lapicTimerDisable(void* pDrvCtrl)[m
     /* Set counter to 0 */[m
     _lapicTimerWrite(pLAPICTimerCtrl->lapicBaseAddress, LAPIC_TICR, 0);[m
 [m
[31m-    KERNEL_CRITICAL_UNLOCK(pLAPICTimerCtrl->lock[cpuId]);[m
[32m+[m[32m    KERNEL_EXIT_CRITICAL_LOCAL(intState);[m
 [m
     KERNEL_TRACE_EVENT(TRACE_X86_LAPIC_TIMER_ENABLED,[m
                        TRACE_X86_LAPIC_TIMER_DISABLE_EXIT,[m
[1mdiff --git a/Source/Kernel/arch/bsp/x86/src/pic.c b/Source/Kernel/arch/bsp/x86/src/pic.c[m
[1mindex 963314c..154e6d1 100644[m
[1m--- a/Source/Kernel/arch/bsp/x86/src/pic.c[m
[1m+++ b/Source/Kernel/arch/bsp/x86/src/pic.c[m
[36m@@ -132,9 +132,6 @@[m [mtypedef struct[m
     /** @brief Tells if the PIC has a slave */[m
     bool_t hasSlave;[m
 [m
[31m-    /** @brief Driver's lock */[m
[31m-    kernel_spinlock_t lock;[m
[31m-[m
     /** @brief PIC IRQ interrupt offset */[m
     uint8_t intOffset;[m
 } pic_controler_t;[m
[36m@@ -278,8 +275,6 @@[m [mstatic OS_RETURN_E _picAttach(const fdt_node_t* pkFdtNode)[m
 [m
     retCode = OS_NO_ERR;[m
 [m
[31m-    KERNEL_SPINLOCK_INIT(sDrvCtrl.lock);[m
[31m-[m
     /* Check for slave */[m
     if(fdtGetProp(pkFdtNode, PIC_FDT_HASSLAVE_PROP, &propLen) != NULL)[m
     {[m
[36m@@ -370,6 +365,7 @@[m [mstatic void _picSetIrqMask(const uint32_t kIrqNumber, const bool_t kEnabled)[m
 {[m
     uint8_t  initMask;[m
     uint32_t cascadingNumber;[m
[32m+[m[32m    uint32_t intState;[m
 [m
     KERNEL_TRACE_EVENT(TRACE_X86_PIC_ENABLED,[m
                        TRACE_X86_PIC_SET_IRQ_MASK_ENTRY,[m
[36m@@ -381,7 +377,7 @@[m [mstatic void _picSetIrqMask(const uint32_t kIrqNumber, const bool_t kEnabled)[m
                "Could not find PIC IRQ",[m
                OS_ERR_NO_SUCH_IRQ);[m
 [m
[31m-    KERNEL_CRITICAL_LOCK(sDrvCtrl.lock);[m
[32m+[m[32m    KERNEL_ENTER_CRITICAL_LOCAL(intState);[m
 [m
     /* Manage master PIC */[m
     if(kIrqNumber < 8)[m
[36m@@ -463,7 +459,7 @@[m [mstatic void _picSetIrqMask(const uint32_t kIrqNumber, const bool_t kEnabled)[m
                  _cpuInB(sDrvCtrl.cpuSlaveDataPort));[m
     }[m
 [m
[31m-    KERNEL_CRITICAL_UNLOCK(sDrvCtrl.lock);[m
[32m+[m[32m    KERNEL_EXIT_CRITICAL_LOCAL(intState);[m
 [m
     KERNEL_TRACE_EVENT(TRACE_X86_PIC_ENABLED,[m
                        TRACE_X86_PIC_SET_IRQ_MASK_EXIT,[m
[36m@@ -474,12 +470,14 @@[m [mstatic void _picSetIrqMask(const uint32_t kIrqNumber, const bool_t kEnabled)[m
 [m
 static void _picSetIrqEOI(const uint32_t kIrqNumber)[m
 {[m
[32m+[m[32m    uint32_t intState;[m
[32m+[m
     KERNEL_TRACE_EVENT(TRACE_X86_PIC_ENABLED,[m
                        TRACE_X86_PIC_SET_IRQ_EOI_ENTRY,[m
                        1,[m
                        kIrqNumber);[m
 [m
[31m-    KERNEL_CRITICAL_LOCK(sDrvCtrl.lock);[m
[32m+[m[32m    KERNEL_ENTER_CRITICAL_LOCAL(intState);[m
 [m
     PIC_ASSERT(kIrqNumber <= PIC_MAX_IRQ_LINE,[m
                "Could not find PIC IRQ",[m
[36m@@ -497,7 +495,7 @@[m [mstatic void _picSetIrqEOI(const uint32_t kIrqNumber)[m
     }[m
     _cpuOutB(PIC_EOI, sDrvCtrl.cpuMasterCommPort);[m
 [m
[31m-    KERNEL_CRITICAL_UNLOCK(sDrvCtrl.lock);[m
[32m+[m[32m    KERNEL_EXIT_CRITICAL_LOCAL(intState);[m
 [m
     KERNEL_TRACE_EVENT(TRACE_X86_PIC_ENABLED,[m
                        TRACE_X86_PIC_SET_IRQ_EOI_EXIT,[m
[1mdiff --git a/Source/Kernel/arch/bsp/x86/src/pit.c b/Source/Kernel/arch/bsp/x86/src/pit.c[m
[1mindex b0fcc71..214c3eb 100644[m
[1m--- a/Source/Kernel/arch/bsp/x86/src/pit.c[m
[1m+++ b/Source/Kernel/arch/bsp/x86/src/pit.c[m
[36m@@ -99,9 +99,6 @@[m [mtypedef struct[m
 [m
     /** @brief Keeps track on the PIT enabled state. */[m
     uint32_t disabledNesting;[m
[31m-[m
[31m-    /** @brief Driver's lock */[m
[31m-    kernel_spinlock_t lock;[m
 } pit_controler_t;[m
 [m
 /*******************************************************************************[m
[36m@@ -296,7 +293,6 @@[m [mstatic OS_RETURN_E _pitAttach(const fdt_node_t* pkFdtNode)[m
         goto ATTACH_END;[m
     }[m
     memset(pDrvCtrl, 0, sizeof(pit_controler_t));[m
[31m-    KERNEL_SPINLOCK_INIT(pDrvCtrl->lock);[m
 [m
     pTimerDrv = kmalloc(sizeof(kernel_timer_t));[m
     if(pTimerDrv == NULL)[m
[36m@@ -460,6 +456,7 @@[m [mstatic void _pitDummyHandler(kernel_thread_t* pCurrThread)[m
 static void _pitEnable(void* pDrvCtrl)[m
 {[m
     pit_controler_t* pPitCtrl;[m
[32m+[m[32m    uint32_t         intState;[m
 [m
     pPitCtrl = GET_CONTROLER(pDrvCtrl);[m
 [m
[36m@@ -468,7 +465,7 @@[m [mstatic void _pitEnable(void* pDrvCtrl)[m
                        1,[m
                        pPitCtrl->disabledNesting);[m
 [m
[31m-    KERNEL_CRITICAL_LOCK(pPitCtrl->lock);[m
[32m+[m[32m    KERNEL_ENTER_CRITICAL_LOCAL(intState);[m
 [m
     if(pPitCtrl->disabledNesting > 0)[m
     {[m
[36m@@ -483,7 +480,7 @@[m [mstatic void _pitEnable(void* pDrvCtrl)[m
         interruptIRQSetMask(pPitCtrl->irqNumber, TRUE);[m
     }[m
 [m
[31m-    KERNEL_CRITICAL_UNLOCK(pPitCtrl->lock);[m
[32m+[m[32m    KERNEL_EXIT_CRITICAL_LOCAL(intState);[m
 [m
     KERNEL_TRACE_EVENT(TRACE_X86_PIT_ENABLED,[m
                        TRACE_X86_PIT_ENABLE_EXIT,[m
[36m@@ -493,6 +490,7 @@[m [mstatic void _pitEnable(void* pDrvCtrl)[m
 [m
 static void _pitDisable(void* pDrvCtrl)[m
 {[m
[32m+[m[32m    uint32_t         intState;[m
     pit_controler_t* pPitCtrl;[m
 [m
     pPitCtrl = GET_CONTROLER(pDrvCtrl);[m
[36m@@ -502,7 +500,7 @@[m [mstatic void _pitDisable(void* pDrvCtrl)[m
                        1,[m
                        pPitCtrl->disabledNesting);[m
 [m
[31m-    KERNEL_CRITICAL_LOCK(pPitCtrl->lock);[m
[32m+[m[32m    KERNEL_ENTER_CRITICAL_LOCAL(intState);[m
 [m
     if(pPitCtrl->disabledNesting < UINT32_MAX)[m
     {[m
[36m@@ -513,7 +511,7 @@[m [mstatic void _pitDisable(void* pDrvCtrl)[m
                  pPitCtrl->disabledNesting);[m
     interruptIRQSetMask(pPitCtrl->irqNumber, FALSE);[m
 [m
[31m-    KERNEL_CRITICAL_UNLOCK(pPitCtrl->lock);[m
[32m+[m[32m    KERNEL_EXIT_CRITICAL_LOCAL(intState);[m
 [m
     KERNEL_TRACE_EVENT(TRACE_X86_PIT_ENABLED,[m
                        TRACE_X86_PIT_DISABLE_EXIT,[m
[36m@@ -526,6 +524,7 @@[m [mstatic void _pitSetFrequency(void* pDrvCtrl, const uint32_t kFreq)[m
 {[m
     uint16_t         tickFreq;[m
     pit_controler_t* pPitCtrl;[m
[32m+[m[32m    uint32_t         intState;[m
 [m
     KERNEL_TRACE_EVENT(TRACE_X86_PIT_ENABLED,[m
                        TRACE_X86_PIT_SET_FREQUENCY_ENTRY,[m
[36m@@ -546,7 +545,7 @@[m [mstatic void _pitSetFrequency(void* pDrvCtrl, const uint32_t kFreq)[m
         return;[m
     }[m
 [m
[31m-    KERNEL_CRITICAL_LOCK(pPitCtrl->lock);[m
[32m+[m[32m    KERNEL_ENTER_CRITICAL_LOCAL(intState);[m
 [m
     pPitCtrl->selectedFrequency = kFreq;[m
 [m
[36m@@ -561,7 +560,7 @@[m [mstatic void _pitSetFrequency(void* pDrvCtrl, const uint32_t kFreq)[m
                  "New PIT frequency set (%d)",[m
                  kFreq);[m
 [m
[31m-    KERNEL_CRITICAL_UNLOCK(pPitCtrl->lock);[m
[32m+[m[32m    KERNEL_EXIT_CRITICAL_LOCAL(intState);[m
 [m
     KERNEL_TRACE_EVENT(TRACE_X86_PIT_ENABLED,[m
                        TRACE_X86_PIT_SET_FREQUENCY_EXIT,[m
[36m@@ -593,6 +592,7 @@[m [mstatic OS_RETURN_E _pitSetHandler(void* pDrvCtrl,[m
 {[m
     OS_RETURN_E      err;[m
     pit_controler_t* pPitCtrl;[m
[32m+[m[32m    uint32_t         intState;[m
 [m
 #ifdef ARCH_32_BITS[m
     KERNEL_TRACE_EVENT(TRACE_X86_PIT_ENABLED,[m
[36m@@ -632,12 +632,12 @@[m [mstatic OS_RETURN_E _pitSetHandler(void* pDrvCtrl,[m
 [m
     _pitDisable(pDrvCtrl);[m
 [m
[31m-    KERNEL_CRITICAL_LOCK(pPitCtrl->lock);[m
[32m+[m[32m    KERNEL_ENTER_CRITICAL_LOCAL(intState);[m
 [m
     err = interruptIRQRegister(pPitCtrl->irqNumber, pHandler);[m
     if(err != OS_NO_ERR)[m
     {[m
[31m-        KERNEL_CRITICAL_UNLOCK(pPitCtrl->lock);[m
[32m+[m[32m        KERNEL_EXIT_CRITICAL_LOCAL(intState);[m
 [m
 #ifdef ARCH_32_BITS[m
         KERNEL_TRACE_EVENT(TRACE_X86_PIT_ENABLED,[m
[36m@@ -658,7 +658,7 @@[m [mstatic OS_RETURN_E _pitSetHandler(void* pDrvCtrl,[m
         return err;[m
     }[m
 [m
[31m-    KERNEL_CRITICAL_UNLOCK(pPitCtrl->lock);[m
[32m+[m[32m    KERNEL_EXIT_CRITICAL_LOCAL(intState);[m
 [m
     KERNEL_DEBUG(PIT_DEBUG_ENABLED,[m
                  MODULE_NAME,[m
[1mdiff --git a/Source/Kernel/arch/cpu/i386/src/cpu.c b/Source/Kernel/arch/cpu/i386/src/cpu.c[m
[1mindex f74d84a..e740476 100644[m
[1m--- a/Source/Kernel/arch/cpu/i386/src/cpu.c[m
[1m+++ b/Source/Kernel/arch/cpu/i386/src/cpu.c[m
[36m@@ -3682,7 +3682,7 @@[m [mvoid cpuApInit(const uint8_t kCpuId)[m
     /* Call scheduler, we should never come back. Restoring a thread should[m
      * enable interrupt.[m
      */[m
[31m-    schedSchedule();[m
[32m+[m[32m    schedScheduleNoInt();[m[41m[m
 [m
     /* Once the scheduler is started, we should never come back here. */[m
     CPU_ASSERT(FALSE, "CPU AP Init Returned", OS_ERR_UNAUTHORIZED_ACTION);[m
[36m@@ -3724,8 +3724,8 @@[m [mvoid cpuDestroyKernelStack(const uintptr_t kStackEndAddr,[m
     size_t    actualSize;[m
 [m
     /* Get the actual base address */[m
[31m-    baseAddress = (kStackEndAddr - kStackSize) & PAGE_SIZE_MASK;[m
[31m-    actualSize  = (kStackSize + PAGE_SIZE_MASK) & PAGE_SIZE_MASK;[m
[32m+[m[32m    baseAddress = (kStackEndAddr - kStackSize) & ~PAGE_SIZE_MASK;[m[41m[m
[32m+[m[32m    actualSize  = (kStackSize + PAGE_SIZE_MASK) & ~PAGE_SIZE_MASK;[m[41m[m
 [m
     memoryKernelUnmapStack(baseAddress, actualSize);[m
 }[m
[1mdiff --git a/Source/Kernel/arch/cpu/i386/src/memory.c b/Source/Kernel/arch/cpu/i386/src/memory.c[m
[1mindex 98bb005..7dad1b4 100644[m
[1m--- a/Source/Kernel/arch/cpu/i386/src/memory.c[m
[1m+++ b/Source/Kernel/arch/cpu/i386/src/memory.c[m
[36m@@ -393,19 +393,6 @@[m [mstatic void _memoryMgrMapKernelRegion(uintptr_t*      pLastSectionStart,[m
  */[m
 static void _memoryMgrInitPaging(void);[m
 [m
[31m-[m
[31m-/**[m
[31m- * @brief Returns the physical address of a virtual address mapped in the[m
[31m- * current page directory.[m
[31m- *[m
[31m- * @details Returns the physical address of a virtual address mapped in the[m
[31m- * current page directory. If not found, KERNEL_VIRTUAL_ADDR_MAX is returned.[m
[31m- *[m
[31m- * @returns The physical address of a virtual address mapped in the[m
[31m- * current page directory. If not found, KERNEL_VIRTUAL_ADDR_MAX is returned.[m
[31m- */[m
[31m-static uintptr_t _memoryMgrGetPhysAddr(const uintptr_t kVirtualAddress);[m
[31m-[m
 /*******************************************************************************[m
  * GLOBAL VARIABLES[m
  ******************************************************************************/[m
[36m@@ -1903,56 +1890,6 @@[m [mstatic void _memoryMgrInitPaging(void)[m
                        0);[m
 }[m
 [m
[31m-static uintptr_t _memoryMgrGetPhysAddr(const uintptr_t kVirtualAddress)[m
[31m-{[m
[31m-    uintptr_t  retPhysAddr;[m
[31m-    uintptr_t* pPgDirRecurEntry;[m
[31m-    uintptr_t* pPgTableRecurEntry;[m
[31m-    uint16_t   pgDirEntry;[m
[31m-    uint16_t   pgTableEntry;[m
[31m-[m
[31m-    KERNEL_TRACE_EVENT(TRACE_X86_MEMMGR_ENABLED,[m
[31m-                       TRACE_X86_MEMMGR_GET_PHYS_ADDR_ENTRY,[m
[31m-                       2,[m
[31m-                       0,[m
[31m-                       kVirtualAddress);[m
[31m-[m
[31m-    retPhysAddr = KERNEL_VIRTUAL_ADDR_MAX;[m
[31m-[m
[31m-    /* Search the entry in the page directory */[m
[31m-    pPgDirRecurEntry = (uintptr_t*)KERNEL_RECUR_PG_DIR_BASE;[m
[31m-[m
[31m-    /* Get entry indexes */[m
[31m-    pgDirEntry   = kVirtualAddress >> PG_DIR_ENTRY_OFFSET;[m
[31m-    pgTableEntry = (kVirtualAddress >> PG_TABLE_ENTRY_OFFSET) &[m
[31m-                   PG_TABLE_ENTRY_OFFSET_MASK;[m
[31m-[m
[31m-    KERNEL_CRITICAL_LOCK(sLock);[m
[31m-[m
[31m-    /* If the entry is empty */[m
[31m-    if((pPgDirRecurEntry[pgDirEntry] & PAGE_FLAG_PRESENT) != 0)[m
[31m-    {[m
[31m-        /* Get page table recursive entry */[m
[31m-        pPgTableRecurEntry = (uintptr_t*)KERNEL_RECUR_PGTABLE_BASE(pgDirEntry);[m
[31m-        if((pPgTableRecurEntry[pgTableEntry] & PAGE_FLAG_PRESENT) != 0)[m
[31m-        {[m
[31m-            retPhysAddr = pPgTableRecurEntry[pgTableEntry] & PG_ENTRY_ADDR_MASK;[m
[31m-        }[m
[31m-    }[m
[31m-[m
[31m-    KERNEL_CRITICAL_UNLOCK(sLock);[m
[31m-[m
[31m-    KERNEL_TRACE_EVENT(TRACE_X86_MEMMGR_ENABLED,[m
[31m-                       TRACE_X86_MEMMGR_GET_PHYS_ADDR_EXIT,[m
[31m-                       4,[m
[31m-                       0,[m
[31m-                       kVirtualAddress,[m
[31m-                       0,[m
[31m-                       retPhysAddr);[m
[31m-[m
[31m-    return retPhysAddr;[m
[31m-}[m
[31m-[m
 void memoryMgrInit(void)[m
 {[m
     KERNEL_TRACE_EVENT(TRACE_X86_MEMMGR_ENABLED,[m
[36m@@ -2236,9 +2173,9 @@[m [mvoid* memoryKernelMapStack(const size_t kSize)[m
             /* Release frames */[m
             for(i = 0; i < mappedCount; ++i)[m
             {[m
[31m-                newFrame = _memoryMgrGetPhysAddr(pageBaseAddress +[m
[31m-                                                 KERNEL_PAGE_SIZE * i);[m
[31m-                MEM_ASSERT(newFrame != KERNEL_VIRTUAL_ADDR_MAX,[m
[32m+[m[32m                newFrame = memoryMgrGetPhysAddr(pageBaseAddress +[m
[32m+[m[32m                                                KERNEL_PAGE_SIZE * i);[m
[32m+[m[32m                MEM_ASSERT(newFrame != MEMMGR_PHYS_ADDR_ERROR,[m
                            "Invalid physical frame",[m
                            OS_ERR_INCORRECT_VALUE);[m
                 _releaseFrames(newFrame, 1);[m
[36m@@ -2288,8 +2225,8 @@[m [mvoid memoryKernelUnmapStack(const uintptr_t kBaseAddress, const size_t kSize)[m
     /* Free the frames and memory */[m
     for(i = 0; i < pageCount; ++i)[m
     {[m
[31m-        frameAddr = _memoryMgrGetPhysAddr(kBaseAddress + KERNEL_PAGE_SIZE * i);[m
[31m-        MEM_ASSERT(frameAddr != KERNEL_VIRTUAL_ADDR_MAX,[m
[32m+[m[32m        frameAddr = memoryMgrGetPhysAddr(kBaseAddress + KERNEL_PAGE_SIZE * i);[m
[32m+[m[32m        MEM_ASSERT(frameAddr != MEMMGR_PHYS_ADDR_ERROR,[m
                    "Invalid physical frame",[m
                    OS_ERR_INCORRECT_VALUE);[m
         _releaseFrames(frameAddr, 1);[m
[36m@@ -2308,4 +2245,57 @@[m [mvoid memoryKernelUnmapStack(const uintptr_t kBaseAddress, const size_t kSize)[m
                        (uint32_t)kBaseAddress);[m
 }[m
 [m
[32m+[m[32muintptr_t memoryMgrGetPhysAddr(const uintptr_t kVirtualAddress)[m
[32m+[m[32m{[m
[32m+[m[32m    uintptr_t  retPhysAddr;[m
[32m+[m[32m    uintptr_t* pPgDirRecurEntry;[m
[32m+[m[32m    uintptr_t* pPgTableRecurEntry;[m
[32m+[m[32m    uint16_t   pgDirEntry;[m
[32m+[m[32m    uint16_t   pgTableEntry;[m
[32m+[m
[32m+[m[32m    KERNEL_TRACE_EVENT(TRACE_X86_MEMMGR_ENABLED,[m
[32m+[m[32m                       TRACE_X86_MEMMGR_GET_PHYS_ADDR_ENTRY,[m
[32m+[m[32m                       2,[m
[32m+[m[32m                       0,[m
[32m+[m[32m                       kVirtualAddress);[m
[32m+[m
[32m+[m[32m    retPhysAddr = MEMMGR_PHYS_ADDR_ERROR;[m
[32m+[m
[32m+[m[32m    /* Search the entry in the page directory */[m
[32m+[m[32m    pPgDirRecurEntry = (uintptr_t*)KERNEL_RECUR_PG_DIR_BASE;[m
[32m+[m
[32m+[m[32m    /* Get entry indexes */[m
[32m+[m[32m    pgDirEntry   = kVirtualAddress >> PG_DIR_ENTRY_OFFSET;[m
[32m+[m[32m    pgTableEntry = (kVirtualAddress >> PG_TABLE_ENTRY_OFFSET) &[m
[32m+[m[32m                   PG_TABLE_ENTRY_OFFSET_MASK;[m
[32m+[m
[32m+[m[32m    KERNEL_CRITICAL_LOCK(sLock);[m
[32m+[m
[32m+[m[32m    /* If the entry is empty */[m
[32m+[m[32m    if((pPgDirRecurEntry[pgDirEntry] & PAGE_FLAG_PRESENT) != 0)[m
[32m+[m[32m    {[m
[32m+[m[32m        /* Get page table recursive entry */[m
[32m+[m[32m        pPgTableRecurEntry = (uintptr_t*)KERNEL_RECUR_PGTABLE_BASE(pgDirEntry);[m
[32m+[m[32m        if((pPgTableRecurEntry[pgTableEntry] & PAGE_FLAG_PRESENT) != 0)[m
[32m+[m[32m        {[m
[32m+[m[32m            retPhysAddr = pPgTableRecurEntry[pgTableEntry] & PG_ENTRY_ADDR_MASK;[m
[32m+[m[32m        }[m
[32m+[m[32m    }[m
[32m+[m
[32m+[m[32m    KERNEL_CRITICAL_UNLOCK(sLock);[m
[32m+[m[32m    if(retPhysAddr != MEMMGR_PHYS_ADDR_ERROR)[m
[32m+[m[32m    {[m
[32m+[m[32m        retPhysAddr |= kVirtualAddress & PAGE_SIZE_MASK;[m
[32m+[m[32m    }[m
[32m+[m
[32m+[m[32m    KERNEL_TRACE_EVENT(TRACE_X86_MEMMGR_ENABLED,[m
[32m+[m[32m                       TRACE_X86_MEMMGR_GET_PHYS_ADDR_EXIT,[m
[32m+[m[32m                       4,[m
[32m+[m[32m                       0,[m
[32m+[m[32m                       kVirtualAddress,[m
[32m+[m[32m                       0,[m
[32m+[m[32m                       retPhysAddr);[m
[32m+[m[32m    return retPhysAddr;[m
[32m+[m[32m}[m
[32m+[m
 /************************************ EOF *************************************/[m
\ No newline at end of file[m
[1mdiff --git a/Source/Kernel/arch/cpu/includes/critical.h b/Source/Kernel/arch/cpu/includes/critical.h[m
[1mindex 3a7aeb4..e9bb19b 100644[m
[1m--- a/Source/Kernel/arch/cpu/includes/critical.h[m
[1m+++ b/Source/Kernel/arch/cpu/includes/critical.h[m
[36m@@ -50,12 +50,12 @@[m
  * @details Enters a critical section in the kernel. Save interrupt state and[m
  * disables interrupts.[m
  */[m
[31m-#define ENTER_CRITICAL(INT_STATE) {                  \[m
[31m-    INT_STATE = interruptDisable();                  \[m
[31m-    KERNEL_TRACE_EVENT(TRACE_CRITICAL_SECTION_ENABLED,        \[m
[31m-                       TRACE_CPU_ENTER_CRITICAL,     \[m
[31m-                       1,                            \[m
[31m-                       INT_STATE);                   \[m
[32m+[m[32m#define KERNEL_ENTER_CRITICAL_LOCAL(INT_STATE) {                    \[m
[32m+[m[32m    INT_STATE = interruptDisable();                                 \[m
[32m+[m[32m    KERNEL_TRACE_EVENT(TRACE_CRITICAL_SECTION_ENABLED,              \[m
[32m+[m[32m                       TRACE_CPU_ENTER_CRITICAL,                    \[m
[32m+[m[32m                       1,                                           \[m
[32m+[m[32m                       INT_STATE);                                  \[m
 }[m
 [m
 /**[m
[36m@@ -66,12 +66,12 @@[m
  * @details Exits a critical section in the kernel. Restore the previous[m
  * interrupt state.[m
  */[m
[31m-#define EXIT_CRITICAL(INT_STATE) {                  \[m
[31m-    interruptRestore(INT_STATE);                    \[m
[31m-    KERNEL_TRACE_EVENT(TRACE_CRITICAL_SECTION_ENABLED,       \[m
[31m-                       TRACE_CPU_EXIT_CRITICAL,     \[m
[31m-                       1,                           \[m
[31m-                       INT_STATE);                  \[m
[32m+[m[32m#define KERNEL_EXIT_CRITICAL_LOCAL(INT_STATE) {                 \[m
[32m+[m[32m    interruptRestore(INT_STATE);                                \[m
[32m+[m[32m    KERNEL_TRACE_EVENT(TRACE_CRITICAL_SECTION_ENABLED,          \[m
[32m+[m[32m                       TRACE_CPU_EXIT_CRITICAL,                 \[m
[32m+[m[32m                       1,                                       \[m
[32m+[m[32m                       INT_STATE);                              \[m
 }[m
 [m
 /**[m
[36m@@ -81,13 +81,13 @@[m
  *[m
  * @param[in, out] LOCK The lock to lock.[m
 */[m
[31m-#define KERNEL_CRITICAL_LOCK(LOCK) {                \[m
[31m-    ENTER_CRITICAL((LOCK).intState[cpuGetId()]);                \[m
[31m-    spinlockAcquire(&((LOCK).lock));             \[m
[31m-    KERNEL_TRACE_EVENT(TRACE_CRITICAL_SECTION_ENABLED,       \[m
[31m-                       TRACE_CPU_SPINLOCK_LOCK,     \[m
[31m-                       1,                           \[m
[31m-                       (LOCK).lock);                       \[m
[32m+[m[32m#define KERNEL_CRITICAL_LOCK(LOCK) {                            \[m
[32m+[m[32m    KERNEL_ENTER_CRITICAL_LOCAL((LOCK).intState[cpuGetId()]);   \[m
[32m+[m[32m    spinlockAcquire(&((LOCK).lock));                            \[m
[32m+[m[32m    KERNEL_TRACE_EVENT(TRACE_CRITICAL_SECTION_ENABLED,          \[m
[32m+[m[32m                       TRACE_CPU_SPINLOCK_LOCK,                 \[m
[32m+[m[32m                       1,                                       \[m
[32m+[m[32m                       (LOCK).lock);                            \[m
 }[m
 [m
 /**[m
[36m@@ -97,13 +97,13 @@[m
  *[m
  * @param[out] LOCK The lock to unlock.[m
 */[m
[31m-#define KERNEL_CRITICAL_UNLOCK(LOCK) {                  \[m
[31m-    spinlockRelease(&((LOCK).lock));                 \[m
[31m-    EXIT_CRITICAL((LOCK).intState[cpuGetId()]);                     \[m
[31m-    KERNEL_TRACE_EVENT(TRACE_CRITICAL_SECTION_ENABLED,           \[m
[31m-                       TRACE_CPU_SPINLOCK_UNLOCK,       \[m
[31m-                       1,                               \[m
[31m-                       LOCK);                           \[m
[32m+[m[32m#define KERNEL_CRITICAL_UNLOCK(LOCK) {                          \[m
[32m+[m[32m    spinlockRelease(&((LOCK).lock));                            \[m
[32m+[m[32m    KERNEL_EXIT_CRITICAL_LOCAL((LOCK).intState[cpuGetId()]);    \[m
[32m+[m[32m    KERNEL_TRACE_EVENT(TRACE_CRITICAL_SECTION_ENABLED,          \[m
[32m+[m[32m                       TRACE_CPU_SPINLOCK_UNLOCK,               \[m
[32m+[m[32m                       1,                                       \[m
[32m+[m[32m                       LOCK);                                   \[m
 }[m
 [m
 /*******************************************************************************[m
[1mdiff --git a/Source/Kernel/arch/cpu/includes/memory.h b/Source/Kernel/arch/cpu/includes/memory.h[m
[1mindex b6bcc1d..67d6129 100644[m
[1m--- a/Source/Kernel/arch/cpu/includes/memory.h[m
[1m+++ b/Source/Kernel/arch/cpu/includes/memory.h[m
[36m@@ -54,6 +54,9 @@[m
 /** @brief Page size mask */[m
 #define PAGE_SIZE_MASK 0xFFF[m
 [m
[32m+[m[32m/** @brief Defines the error for physical address */[m
[32m+[m[32m#define MEMMGR_PHYS_ADDR_ERROR ((uintptr_t)0xFFFFFFFFFFFFFFFFULL)[m
[32m+[m
 /* @brief  */[m
 /*******************************************************************************[m
  * STRUCTURES AND TYPES[m
[36m@@ -158,6 +161,18 @@[m [mvoid* memoryKernelMap(const void*    kPhysicalAddress,[m
  */[m
 OS_RETURN_E memoryKernelUnmap(const void* kVirtualAddress, const size_t kSize);[m
 [m
[32m+[m[32m/**[m
[32m+[m[32m * @brief Returns the physical address of a virtual address mapped in the[m
[32m+[m[32m * current page directory.[m
[32m+[m[32m *[m
[32m+[m[32m * @details Returns the physical address of a virtual address mapped in the[m
[32m+[m[32m * current page directory. If not found, MEMMGR_PHYS_ADDR_ERROR is returned.[m
[32m+[m[32m *[m
[32m+[m[32m * @returns The physical address of a virtual address mapped in the[m
[32m+[m[32m * current page directory. If not found, MEMMGR_PHYS_ADDR_ERROR is returned.[m
[32m+[m[32m */[m
[32m+[m[32muintptr_t memoryMgrGetPhysAddr(const uintptr_t kVirtualAddress);[m
[32m+[m
 #endif /* #ifndef __MEMORY_MGR_ */[m
 [m
 /************************************ EOF *************************************/[m
\ No newline at end of file[m
[1mdiff --git a/Source/Kernel/arch/cpu/x86_64/src/cpu.c b/Source/Kernel/arch/cpu/x86_64/src/cpu.c[m
[1mindex 70dba14..bba39ad 100644[m
[1m--- a/Source/Kernel/arch/cpu/x86_64/src/cpu.c[m
[1m+++ b/Source/Kernel/arch/cpu/x86_64/src/cpu.c[m
[36m@@ -3749,7 +3749,7 @@[m [mvoid cpuApInit(const uint8_t kCpuId)[m
     /* Call scheduler, we should never come back. Restoring a thread should[m
      * enable interrupt.[m
      */[m
[31m-    schedSchedule();[m
[32m+[m[32m    schedScheduleNoInt();[m[41m[m
 [m
     /* Once the scheduler is started, we should never come back here. */[m
     CPU_ASSERT(FALSE, "CPU AP Init Returned", OS_ERR_UNAUTHORIZED_ACTION);[m
[36m@@ -3768,6 +3768,10 @@[m [mvoid cpuInvalidateTlbEntry(const uintptr_t kVirtAddress)[m
 uintptr_t cpuCreateKernelStack(const size_t kStackSize)[m
 {[m
     uintptr_t stackAddr;[m
[32m+[m[32m    uintptr_t newSize;[m[41m[m
[32m+[m[41m[m
[32m+[m[32m    /* Align stack on 4K */[m[41m[m
[32m+[m[32m    newSize = (kStackSize + PAGE_SIZE_MASK) & ~PAGE_SIZE_MASK;[m[41m[m
 [m
     /* Request to map the stack */[m
     stackAddr = (uintptr_t)memoryKernelMapStack(kStackSize);[m
[36m@@ -3779,7 +3783,7 @@[m [muintptr_t cpuCreateKernelStack(const size_t kStackSize)[m
     }[m
 [m
     /* Set end address and align on 16 bytes */[m
[31m-    stackAddr = ((stackAddr + kStackSize) - 0xFULL) & ~0xFULL;[m
[32m+[m[32m    stackAddr = (stackAddr + newSize - 0xFULL);[m[41m[m
 [m
     return stackAddr;[m
 }[m
[36m@@ -3791,8 +3795,8 @@[m [mvoid cpuDestroyKernelStack(const uintptr_t kStackEndAddr,[m
     size_t    actualSize;[m
 [m
     /* Get the actual base address */[m
[31m-    baseAddress = (kStackEndAddr - kStackSize) & PAGE_SIZE_MASK;[m
[31m-    actualSize  = (kStackSize + PAGE_SIZE_MASK) & PAGE_SIZE_MASK;[m
[32m+[m[32m    actualSize  = (kStackSize + PAGE_SIZE_MASK) & ~PAGE_SIZE_MASK;[m[41m[m
[32m+[m[32m    baseAddress = kStackEndAddr + 0xFULL - kStackSize;[m[41m[m
 [m
     memoryKernelUnmapStack(baseAddress, actualSize);[m
 }[m
[1mdiff --git a/Source/Kernel/arch/cpu/x86_64/src/memory.c b/Source/Kernel/arch/cpu/x86_64/src/memory.c[m
[1mindex e0fa818..2bf478a 100644[m
[1m--- a/Source/Kernel/arch/cpu/x86_64/src/memory.c[m
[1m+++ b/Source/Kernel/arch/cpu/x86_64/src/memory.c[m
[36m@@ -426,19 +426,6 @@[m [mstatic void _memoryMgrMapKernelRegion(uintptr_t*      pLastSectionStart,[m
  */[m
 static void _memoryMgrInitPaging(void);[m
 [m
[31m-[m
[31m-/**[m
[31m- * @brief Returns the physical address of a virtual address mapped in the[m
[31m- * current page directory.[m
[31m- *[m
[31m- * @details Returns the physical address of a virtual address mapped in the[m
[31m- * current page directory. If not found, KERNEL_VIRTUAL_ADDR_MAX is returned.[m
[31m- *[m
[31m- * @returns The physical address of a virtual address mapped in the[m
[31m- * current page directory. If not found, KERNEL_VIRTUAL_ADDR_MAX is returned.[m
[31m- */[m
[31m-static uintptr_t _memoryMgrGetPhysAddr(const uintptr_t kVirtualAddress);[m
[31m-[m
 /*******************************************************************************[m
  * GLOBAL VARIABLES[m
  ******************************************************************************/[m
[36m@@ -2344,76 +2331,6 @@[m [mstatic void _memoryMgrInitPaging(void)[m
                        0);[m
 }[m
 [m
[31m-static uintptr_t _memoryMgrGetPhysAddr(const uintptr_t kVirtualAddress)[m
[31m-{[m
[31m-    uintptr_t  retPhysAddr;[m
[31m-    uintptr_t* pRecurTableEntry;[m
[31m-    uint16_t   pmlEntry[4];[m
[31m-    int8_t     j;[m
[31m-[m
[31m-    KERNEL_TRACE_EVENT(TRACE_X86_MEMMGR_ENABLED,[m
[31m-                       TRACE_X86_MEMMGR_GET_PHYS_ADDR_ENTRY,[m
[31m-                       2,[m
[31m-                       (uint32_t)(kVirtualAddress >> 32),[m
[31m-                       (uint32_t)kVirtualAddress);[m
[31m-[m
[31m-    retPhysAddr = KERNEL_VIRTUAL_ADDR_MAX;[m
[31m-[m
[31m-    KERNEL_CRITICAL_LOCK(sLock);[m
[31m-    pmlEntry[3] = (kVirtualAddress >> PML4_ENTRY_OFFSET) &[m
[31m-                    PG_ENTRY_OFFSET_MASK;[m
[31m-    pmlEntry[2] = (kVirtualAddress >> PML3_ENTRY_OFFSET) &[m
[31m-                    PG_ENTRY_OFFSET_MASK;[m
[31m-    pmlEntry[1] = (kVirtualAddress >> PML2_ENTRY_OFFSET) &[m
[31m-                    PG_ENTRY_OFFSET_MASK;[m
[31m-    pmlEntry[0] = (kVirtualAddress >> PML1_ENTRY_OFFSET) &[m
[31m-                    PG_ENTRY_OFFSET_MASK;[m
[31m-[m
[31m-    for(j = 3; j >= 0; --j)[m
[31m-    {[m
[31m-        if(j == 3)[m
[31m-        {[m
[31m-            pRecurTableEntry = (uintptr_t*)KERNEL_RECUR_PML4_DIR_BASE;[m
[31m-        }[m
[31m-        else if(j == 2)[m
[31m-        {[m
[31m-            pRecurTableEntry =[m
[31m-                (uintptr_t*)KERNEL_RECUR_PML3_DIR_BASE(pmlEntry[3]);[m
[31m-        }[m
[31m-        else if(j == 1)[m
[31m-        {[m
[31m-            pRecurTableEntry =[m
[31m-                (uintptr_t*)KERNEL_RECUR_PML2_DIR_BASE(pmlEntry[3],[m
[31m-                                                       pmlEntry[2]);[m
[31m-        }[m
[31m-[m
[31m-        if((pRecurTableEntry[pmlEntry[j]] & PAGE_FLAG_PRESENT) != 0)[m
[31m-        {[m
[31m-            if(j == 0)[m
[31m-            {[m
[31m-                retPhysAddr = (pRecurTableEntry[pmlEntry[j]] &[m
[31m-                               sPhysAddressWidthMask) & ~PAGE_SIZE_MASK;[m
[31m-            }[m
[31m-        }[m
[31m-        else[m
[31m-        {[m
[31m-            break;[m
[31m-        }[m
[31m-    }[m
[31m-[m
[31m-    KERNEL_CRITICAL_UNLOCK(sLock);[m
[31m-[m
[31m-    KERNEL_TRACE_EVENT(TRACE_X86_MEMMGR_ENABLED,[m
[31m-                       TRACE_X86_MEMMGR_GET_PHYS_ADDR_EXIT,[m
[31m-                       4,[m
[31m-                       (uint32_t)(kVirtualAddress >> 32),[m
[31m-                       (uint32_t)kVirtualAddress,[m
[31m-                       (uint32_t)(retPhysAddr >> 32),[m
[31m-                       (uint32_t)retPhysAddr);[m
[31m-[m
[31m-    return retPhysAddr;[m
[31m-}[m
[31m-[m
 void memoryMgrInit(void)[m
 {[m
     KERNEL_TRACE_EVENT(TRACE_X86_MEMMGR_ENABLED,[m
[36m@@ -2700,9 +2617,9 @@[m [mvoid* memoryKernelMapStack(const size_t kSize)[m
             /* Release frames */[m
             for(i = 0; i < mappedCount; ++i)[m
             {[m
[31m-                newFrame = _memoryMgrGetPhysAddr(pageBaseAddress +[m
[31m-                                                 KERNEL_PAGE_SIZE * i);[m
[31m-                MEM_ASSERT(newFrame != KERNEL_VIRTUAL_ADDR_MAX,[m
[32m+[m[32m                newFrame = memoryMgrGetPhysAddr(pageBaseAddress +[m
[32m+[m[32m                                                KERNEL_PAGE_SIZE * i);[m
[32m+[m[32m                MEM_ASSERT(newFrame != MEMMGR_PHYS_ADDR_ERROR,[m
                            "Invalid physical frame",[m
                            OS_ERR_INCORRECT_VALUE);[m
                 _releaseFrames(newFrame, 1);[m
[36m@@ -2752,8 +2669,8 @@[m [mvoid memoryKernelUnmapStack(const uintptr_t kBaseAddress, const size_t kSize)[m
     /* Free the frames and memory */[m
     for(i = 0; i < pageCount; ++i)[m
     {[m
[31m-        frameAddr = _memoryMgrGetPhysAddr(kBaseAddress + KERNEL_PAGE_SIZE * i);[m
[31m-        MEM_ASSERT(frameAddr != KERNEL_VIRTUAL_ADDR_MAX,[m
[32m+[m[32m        frameAddr = memoryMgrGetPhysAddr(kBaseAddress + KERNEL_PAGE_SIZE * i);[m
[32m+[m[32m        MEM_ASSERT(frameAddr != MEMMGR_PHYS_ADDR_ERROR,[m
                    "Invalid physical frame",[m
                    OS_ERR_INCORRECT_VALUE);[m
         _releaseFrames(frameAddr, 1);[m
[36m@@ -2772,4 +2689,85 @@[m [mvoid memoryKernelUnmapStack(const uintptr_t kBaseAddress, const size_t kSize)[m
                        (uint32_t)kBaseAddress);[m
 }[m
 [m
[32m+[m[32muintptr_t memoryMgrGetPhysAddr(const uintptr_t kVirtualAddress)[m
[32m+[m[32m{[m
[32m+[m[32m    uintptr_t  retPhysAddr;[m
[32m+[m[32m    uintptr_t* pRecurTableEntry;[m
[32m+[m[32m    uint16_t   pmlEntry[4];[m
[32m+[m[32m    int8_t     j;[m
[32m+[m
[32m+[m[32m    KERNEL_TRACE_EVENT(TRACE_X86_MEMMGR_ENABLED,[m
[32m+[m[32m                       TRACE_X86_MEMMGR_GET_PHYS_ADDR_ENTRY,[m
[32m+[m[32m                       2,[m
[32m+[m[32m                       (uint32_t)(kVirtualAddress >> 32),[m
[32m+[m[32m                       (uint32_t)kVirtualAddress);[m
[32m+[m
[32m+[m[32m    retPhysAddr = MEMMGR_PHYS_ADDR_ERROR;[m
[32m+[m
[32m+[m[32m    KERNEL_CRITICAL_LOCK(sLock);[m
[32m+[m[32m    pmlEntry[3] = (kVirtualAddress >> PML4_ENTRY_OFFSET) &[m
[32m+[m[32m                    PG_ENTRY_OFFSET_MASK;[m
[32m+[m[32m    pmlEntry[2] = (kVirtualAddress >> PML3_ENTRY_OFFSET) &[m
[32m+[m[32m                    PG_ENTRY_OFFSET_MASK;[m
[32m+[m[32m    pmlEntry[1] = (kVirtualAddress >> PML2_ENTRY_OFFSET) &[m
[32m+[m[32m                    PG_ENTRY_OFFSET_MASK;[m
[32m+[m[32m    pmlEntry[0] = (kVirtualAddress >> PML1_ENTRY_OFFSET) &[m
[32m+[m[32m                    PG_ENTRY_OFFSET_MASK;[m
[32m+[m
[32m+[m[32m    for(j = 3; j >= 0; --j)[m
[32m+[m[32m    {[m
[32m+[m[32m        if(j == 3)[m
[32m+[m[32m        {[m
[32m+[m[32m            pRecurTableEntry = (uintptr_t*)KERNEL_RECUR_PML4_DIR_BASE;[m
[32m+[m[32m        }[m
[32m+[m[32m        else if(j == 2)[m
[32m+[m[32m        {[m
[32m+[m[32m            pRecurTableEntry =[m
[32m+[m[32m                (uintptr_t*)KERNEL_RECUR_PML3_DIR_BASE(pmlEntry[3]);[m
[32m+[m[32m        }[m
[32m+[m[32m        else if(j == 1)[m
[32m+[m[32m        {[m
[32m+[m[32m            pRecurTableEntry =[m
[32m+[m[32m                (uintptr_t*)KERNEL_RECUR_PML2_DIR_BASE(pmlEntry[3],[m
[32m+[m[32m                                                       pmlEntry[2]);[m
[32m+[m[32m        }[m
[32m+[m[32m        if(j == 0)[m
[32m+[m[32m        {[m
[32m+[m[32m            pRecurTableEntry =[m
[32m+[m[32m            (uintptr_t*)KERNEL_RECUR_PML1_DIR_BASE(pmlEntry[3],[m
[32m+[m[32m                                                   pmlEntry[2],[m
[32m+[m[32m                                                   pmlEntry[1]);[m
[32m+[m[32m        }[m
[32m+[m
[32m+[m[32m        if((pRecurTableEntry[pmlEntry[j]] & PAGE_FLAG_PRESENT) != 0)[m
[32m+[m[32m        {[m
[32m+[m[32m            if(j == 0)[m
[32m+[m[32m            {[m
[32m+[m[32m                retPhysAddr = (pRecurTableEntry[pmlEntry[j]] &[m
[32m+[m[32m                               sPhysAddressWidthMask) & ~PAGE_SIZE_MASK;[m
[32m+[m[32m            }[m
[32m+[m[32m        }[m
[32m+[m[32m        else[m
[32m+[m[32m        {[m
[32m+[m[32m            break;[m
[32m+[m[32m        }[m
[32m+[m[32m    }[m
[32m+[m
[32m+[m[32m    KERNEL_CRITICAL_UNLOCK(sLock);[m
[32m+[m
[32m+[m[32m    if(retPhysAddr != MEMMGR_PHYS_ADDR_ERROR)[m
[32m+[m[32m    {[m
[32m+[m[32m        retPhysAddr |= kVirtualAddress & PAGE_SIZE_MASK;[m
[32m+[m[32m    }[m
[32m+[m
[32m+[m[32m    KERNEL_TRACE_EVENT(TRACE_X86_MEMMGR_ENABLED,[m
[32m+[m[32m                       TRACE_X86_MEMMGR_GET_PHYS_ADDR_EXIT,[m
[32m+[m[32m                       4,[m
[32m+[m[32m                       (uint32_t)(kVirtualAddress >> 32),[m
[32m+[m[32m                       (uint32_t)kVirtualAddress,[m
[32m+[m[32m                       (uint32_t)(retPhysAddr >> 32),[m
[32m+[m[32m                       (uint32_t)retPhysAddr);[m
[32m+[m
[32m+[m[32m    return retPhysAddr;[m
[32m+[m[32m}[m
 /************************************ EOF *************************************/[m
\ No newline at end of file[m
[1mdiff --git a/Source/Kernel/arch/cpu/x86_64/src/panic.c b/Source/Kernel/arch/cpu/x86_64/src/panic.c[m
[1mindex 0d5e366..6510999 100644[m
[1m--- a/Source/Kernel/arch/cpu/x86_64/src/panic.c[m
[1m+++ b/Source/Kernel/arch/cpu/x86_64/src/panic.c[m
[36m@@ -417,6 +417,8 @@[m [mstatic void _printStackTrace(uintptr_t* lastRBP)[m
     {[m
         callAddr = *(lastRBP + 1);[m
 [m
[32m+[m[32m        if(callAddr == 0x0) break;[m
[32m+[m
         kprintfPanic("[%u] 0x%p", i, callAddr);[m
         if(i != 0 && i % 2 == 0)[m
         {[m
[1mdiff --git a/Source/Kernel/core/includes/ctrl_block.h b/Source/Kernel/core/includes/ctrl_block.h[m
[1mindex c6ce35a..19ad80e 100644[m
[1m--- a/Source/Kernel/core/includes/ctrl_block.h[m
[1m+++ b/Source/Kernel/core/includes/ctrl_block.h[m
[36m@@ -69,6 +69,13 @@[m [mtypedef enum[m
     THREAD_WAIT_TYPE_IO[m
 } THREAD_WAIT_TYPE_E;[m
 [m
[32m+[m[32m/** @brief Defines the type of waiting resource */[m
[32m+[m[32mtypedef enum[m
[32m+[m[32m{[m
[32m+[m[32m    /** @brief Thread is waiting on a futex */[m
[32m+[m[32m    THREAD_WAIT_RESOURCE_FUTEX,[m
[32m+[m[32m} THREAD_WAIT_RESOURCE_TYPE_E;[m
[32m+[m
 /** @brief Defines the possitble return state of a thread. */[m
 typedef enum[m
 {[m
[36m@@ -121,21 +128,6 @@[m [mtypedef struct kernel_thread_t[m
     /** @brief Thread's type. */[m
     THREAD_TYPE_E type;[m
 [m
[31m-    /**************************************[m
[31m-     * State management[m
[31m-     *************************************/[m
[31m-[m
[31m-    /** @brief Thread's current priority. */[m
[31m-    uint8_t priority;[m
[31m-[m
[31m-    /** @brief Thread's current state. */[m
[31m-    THREAD_STATE_E state;[m
[31m-[m
[31m-    /** @brief Thread's wait type. This is inly relevant when the thread's state[m
[31m-     * is THREAD_STATE_WAITING.[m
[31m-     */[m
[31m-    THREAD_WAIT_TYPE_E blockType;[m
[31m-[m
     /**************************************[m
      * System interface[m
      *************************************/[m
[36m@@ -191,6 +183,23 @@[m [mtypedef struct kernel_thread_t[m
     /**************************************[m
      * Scheduler management[m
      *************************************/[m
[32m+[m[32m    /** @brief Thread's current priority. */[m
[32m+[m[32m    uint8_t priority;[m
[32m+[m
[32m+[m[32m    /** @brief Thread's current state. */[m
[32m+[m[32m    THREAD_STATE_E state;[m
[32m+[m
[32m+[m[32m    /** @brief Thread's wait type. This is inly relevant when the thread's state[m
[32m+[m[32m     * is THREAD_STATE_WAITING.[m
[32m+[m[32m     */[m
[32m+[m[32m    THREAD_WAIT_TYPE_E blockType;[m
[32m+[m
[32m+[m[32m    /** @brief Type of resource the thread is blocked on. */[m
[32m+[m[32m    THREAD_WAIT_RESOURCE_TYPE_E resourceBlockType;[m
[32m+[m
[32m+[m[32m    /** @brief Blocking resource */[m
[32m+[m[32m    void* pBlockingResource;[m
[32m+[m
     /** @brief Associated queue node in the scheduler */[m
     void* pThreadNode;[m
 [m
[1mdiff --git a/Source/Kernel/core/includes/kerror.h b/Source/Kernel/core/includes/kerror.h[m
[1mindex 2a464b7..08feb74 100644[m
[1m--- a/Source/Kernel/core/includes/kerror.h[m
[1m+++ b/Source/Kernel/core/includes/kerror.h[m
[36m@@ -60,6 +60,12 @@[m [mtypedef enum[m
     OS_ERR_NOT_SUPPORTED                   = 10,[m
     /** @brief Memory mapping already exists */[m
     OS_ERR_MAPPING_ALREADY_EXISTS          = 11,[m
[32m+[m[32m    /** @brief Identifier not found */[m[41m[m
[32m+[m[32m    OS_ERR_NO_SUCH_ID                      = 12,[m[41m[m
[32m+[m[32m    /** @brief The resource was destroyed */[m[41m[m
[32m+[m[32m    OS_ERR_DESTROYED                       = 13,[m[41m[m
[32m+[m[32m    /** @brief The resource was not blocked */[m[41m[m
[32m+[m[32m    OS_ERR_NOT_BLOCKED                     = 14,[m[41m[m
 } OS_RETURN_E;[m
 [m
 /*******************************************************************************[m
[1mdiff --git a/Source/Kernel/core/includes/kqueue.h b/Source/Kernel/core/includes/kqueue.h[m
[1mindex 1946d17..42a3297 100644[m
[1m--- a/Source/Kernel/core/includes/kqueue.h[m
[1m+++ b/Source/Kernel/core/includes/kqueue.h[m
[36m@@ -49,10 +49,10 @@[m [mtypedef struct kqueue_node[m
     struct kqueue_node* pPrev;[m
 [m
     /** @brief Tell if the node is present in a queue or stands alone. */[m
[31m-    bool_t enlisted;[m
[32m+[m[32m    volatile bool_t enlisted;[m
 [m
     /** @brief Node's priority, used when the queue is a priority queue. */[m
[31m-    uint64_t priority;[m
[32m+[m[32m    volatile uint64_t priority;[m
 [m
     /** @brief Node's data pointer. Store the address of the contained data. */[m
     void* pData;[m
[36m@@ -67,7 +67,7 @@[m [mtypedef struct[m
     kqueue_node_t* pTail;[m
 [m
     /** @brief Current queue's size. */[m
[31m-    size_t size;[m
[32m+[m[32m    volatile size_t size;[m
 [m
     /** @brief Queue's lock */[m
     kernel_spinlock_t lock;[m
[36m@@ -110,6 +110,19 @@[m [mtypedef struct[m
  */[m
 kqueue_node_t* kQueueCreateNode(void* pData);[m
 [m
[32m+[m[32m/**[m
[32m+[m[32m * @brief Initializes a new queue node.[m
[32m+[m[32m *[m
[32m+[m[32m * @details Initializes a node ready to be inserted in a queue. The data can be[m
[32m+[m[32m * modified later by accessing the data field of the node structure.[m
[32m+[m[32m *[m
[32m+[m[32m * @warning A node should be only used in one queue at most.[m
[32m+[m[32m *[m
[32m+[m[32m * @param[in] pNode The pointer to the node to initialize to carry in the node.[m
[32m+[m[32m * @param[in] pData The pointer to the data to carry in the node.[m
[32m+[m[32m */[m
[32m+[m[32mvoid kQueueInitNode(kqueue_node_t* pNode, void* pData);[m
[32m+[m
 /**[m
  * @brief Deletes a queue node.[m
  *[m
[1mdiff --git a/Source/Kernel/core/includes/scheduler.h b/Source/Kernel/core/includes/scheduler.h[m
[1mindex 8459e5e..5b80d67 100644[m
[1m--- a/Source/Kernel/core/includes/scheduler.h[m
[1m+++ b/Source/Kernel/core/includes/scheduler.h[m
[36m@@ -88,7 +88,17 @@[m [mvoid schedInit(void);[m
  *[m
  * @warning The current thread's context must be saved before calling this[m
  * function. Usually, this function is only called in interrupt handlers after[m
[31m- * the thread's context was saved.[m
[32m+[m[32m * the thread's context was saved. Use schedSchedule to save the context.[m
[32m+[m[32m */[m
[32m+[m
[32m+[m[32mvoid schedScheduleNoInt(void);[m
[32m+[m
[32m+[m[32m/**[m
[32m+[m[32m * @brief Calls the scheduler dispatch function by generating an interrupt.[m
[32m+[m[32m *[m
[32m+[m[32m * @details Calls the scheduler dispatch function by generating an interrupt.[m
[32m+[m[32m * This function will select the next thread to schedule and execute it. The[m
[32m+[m[32m * context of the calling thread is saved before scheduling.[m
  */[m
 [m
 void schedSchedule(void);[m
[36m@@ -117,7 +127,7 @@[m [mvoid schedScheduleHandler(kernel_thread_t* pThread);[m
  *[m
  * @param[in] pThread The thread to release.[m
  */[m
[31m-void releaseThread(kernel_thread_t* pThread);[m
[32m+[m[32mvoid schedReleaseThread(kernel_thread_t* pThread);[m
 [m
 /**[m
  * @brief Puts the calling thread to sleep.[m
[1mdiff --git a/Source/Kernel/core/src/exceptions.c b/Source/Kernel/core/src/exceptions.c[m
[1mindex 67728ea..4eb648b 100644[m
[1m--- a/Source/Kernel/core/src/exceptions.c[m
[1m+++ b/Source/Kernel/core/src/exceptions.c[m
[36m@@ -157,8 +157,6 @@[m [mvoid exceptionInit(void)[m
                "Could not initialize exception manager.",[m
                err);[m
 [m
[31m-    TEST_POINT_FUNCTION_CALL(exception_test, TEST_EXCEPTION_ENABLED);[m
[31m-[m
     KERNEL_TRACE_EVENT(TRACE_EXCEPTION_ENABLED, TRACE_EXCEPTION_INIT_EXIT, 0);[m
 }[m
 [m
[1mdiff --git a/Source/Kernel/core/src/interrupts.c b/Source/Kernel/core/src/interrupts.c[m
[1mindex acf6456..271ef1d 100644[m
[1m--- a/Source/Kernel/core/src/interrupts.c[m
[1m+++ b/Source/Kernel/core/src/interrupts.c[m
[36m@@ -241,7 +241,7 @@[m [mvoid interruptMainHandler(void)[m
                        0);[m
 [m
     /* Schedule, we will never return */[m
[31m-    schedSchedule();[m
[32m+[m[32m    schedScheduleNoInt();[m
     PANIC(OS_ERR_UNAUTHORIZED_ACTION,[m
           MODULE_NAME,[m
           "Schedule returned",[m
[36m@@ -290,8 +290,6 @@[m [mvoid interruptInit(void)[m
     sInterruptDriver.pSetIrqEOI           = _initDriverSetIrqEOI;[m
     sInterruptDriver.pSetIrqMask          = _initDriverSetIrqMask;[m
 [m
[31m-    TEST_POINT_FUNCTION_CALL(interrupt_test, TEST_INTERRUPT_ENABLED);[m
[31m-[m
     KERNEL_TRACE_EVENT(TRACE_INTERRUPT_ENABLED, TRACE_INTERRUPT_INIT_EXIT, 0);[m
 }[m
 [m
[1mdiff --git a/Source/Kernel/core/src/kheap.c b/Source/Kernel/core/src/kheap.c[m
[1mindex d99b933..13ea227 100644[m
[1m--- a/Source/Kernel/core/src/kheap.c[m
[1m+++ b/Source/Kernel/core/src/kheap.c[m
[36m@@ -92,6 +92,8 @@[m [mvoid kHeapInit(void)[m
 [m
     KERNEL_SPINLOCK_INIT(sLock);[m
 [m
[32m+[m[32m    TEST_POINT_FUNCTION_CALL(kheap_test, TEST_KHEAP_ENABLED);[m
[32m+[m
     KERNEL_DEBUG(KHEAP_DEBUG_ENABLED, "KHEAP",[m
                  "Kernel Heap Initialized at 0x%p", head);[m
 }[m
[1mdiff --git a/Source/Kernel/core/src/kqueue.c b/Source/Kernel/core/src/kqueue.c[m
[1mindex 1ed2020..1356fab 100644[m
[1m--- a/Source/Kernel/core/src/kqueue.c[m
[1m+++ b/Source/Kernel/core/src/kqueue.c[m
[36m@@ -49,7 +49,8 @@[m
  * CONSTANTS[m
  ******************************************************************************/[m
 [m
[31m-/* None */[m
[32m+[m[32m/** @brief Current module name */[m
[32m+[m[32m#define MODULE_NAME "KQUEUE"[m
 [m
 /*******************************************************************************[m
  * STRUCTURES AND TYPES[m
[36m@@ -76,7 +77,7 @@[m
 #define KQUEUE_ASSERT(COND, MSG, ERROR) {                    \[m
     if((COND) == FALSE)                                      \[m
     {                                                        \[m
[31m-        PANIC(ERROR, "KQUEUE", MSG, TRUE);                   \[m
[32m+[m[32m        PANIC(ERROR, MODULE_NAME, MSG, TRUE);                \[m
     }                                                        \[m
 }[m
 [m
[36m@@ -153,6 +154,32 @@[m [mkqueue_node_t* kQueueCreateNode(void* pData)[m
     return pNewNode;[m
 }[m
 [m
[32m+[m[32mvoid kQueueInitNode(kqueue_node_t* pNode, void* pData)[m
[32m+[m[32m{[m
[32m+[m[32m    KERNEL_TRACE_EVENT(TRACE_KQUEUE_ENABLED,[m
[32m+[m[32m                       TRACE_KQUEUE_INIT_NODE_ENTRY,[m
[32m+[m[32m                       4,[m
[32m+[m[32m                       (uint32_t)(((uint64_t)(uintptr_t)pNode) >> 32),[m
[32m+[m[32m                       (uint32_t)(uintptr_t)pNode,[m
[32m+[m[32m                       (uint32_t)(((uint64_t)(uintptr_t)pData) >> 32),[m
[32m+[m[32m                       (uint32_t)(uintptr_t)pData);[m
[32m+[m
[32m+[m[32m    KQUEUE_ASSERT(pNode != NULL,[m
[32m+[m[32m                  "Initializes a NULL node",[m
[32m+[m[32m                  OS_ERR_NULL_POINTER);[m
[32m+[m
[32m+[m[32m    memset(pNode, 0, sizeof(kqueue_node_t));[m
[32m+[m[32m    pNode->pData = pData;[m
[32m+[m
[32m+[m[32m    KERNEL_TRACE_EVENT(TRACE_KQUEUE_ENABLED,[m
[32m+[m[32m                       TRACE_KQUEUE_INIT_NODE_EXIT,[m
[32m+[m[32m                       4,[m
[32m+[m[32m                       (uint32_t)(((uint64_t)(uintptr_t)pNode) >> 32),[m
[32m+[m[32m                       (uint32_t)(uintptr_t)pNode,[m
[32m+[m[32m                       (uint32_t)(((uint64_t)(uintptr_t)pData) >> 32),[m
[32m+[m[32m                       (uint32_t)(uintptr_t)pData);[m
[32m+[m[32m}[m
[32m+[m
 void kQueueDestroyNode(kqueue_node_t** ppNode)[m
 {[m
 [m
[36m@@ -268,7 +295,7 @@[m [mvoid kQueuePush(kqueue_node_t* pNode, kqueue_t* pQueue)[m
 #endif[m
 [m
     KERNEL_DEBUG(KQUEUE_DEBUG_ENABLED,[m
[31m-                 "KQUEUE",[m
[32m+[m[32m                 MODULE_NAME,[m
                  "KQueue try push knode 0x%p in kqueue 0x%p",[m
                  pNode,[m
                  pQueue);[m
[36m@@ -310,7 +337,7 @@[m [mvoid kQueuePush(kqueue_node_t* pNode, kqueue_t* pQueue)[m
     KERNEL_CRITICAL_UNLOCK(pQueue->lock);[m
 [m
     KERNEL_DEBUG(KQUEUE_DEBUG_ENABLED,[m
[31m-                 "KQUEUE",[m
[32m+[m[32m                 MODULE_NAME,[m
                  "KQueue pushed knode 0x%p in kqueue 0x%p",[m
                  pNode,[m
                  pQueue);[m
[36m@@ -361,7 +388,7 @@[m [mvoid kQueuePushPrio(kqueue_node_t* pNode,[m
 #endif[m
 [m
     KERNEL_DEBUG(KQUEUE_DEBUG_ENABLED,[m
[31m-                 "KQUEUE",[m
[32m+[m[32m                 MODULE_NAME,[m
                  "KQueue try push prio knode 0x%p in kqueue 0x%p",[m
                  pNode,[m
                  pQueue);[m
[36m@@ -426,7 +453,7 @@[m [mvoid kQueuePushPrio(kqueue_node_t* pNode,[m
 [m
     KERNEL_CRITICAL_UNLOCK(pQueue->lock);[m
 [m
[31m-    KERNEL_DEBUG(KQUEUE_DEBUG_ENABLED, "KQUEUE",[m
[32m+[m[32m    KERNEL_DEBUG(KQUEUE_DEBUG_ENABLED, MODULE_NAME,[m
                  "KQueue pushed knode 0x%p in kqueue 0x%p", pNode, pQueue);[m
 [m
 #ifdef ARCH_32_BITS[m
[36m@@ -469,7 +496,7 @@[m [mkqueue_node_t* kQueuePop(kqueue_t* pQueue)[m
 #endif[m
 [m
     KERNEL_DEBUG(KQUEUE_DEBUG_ENABLED,[m
[31m-                 "KQUEUE",[m
[32m+[m[32m                 MODULE_NAME,[m
                  "KQueue try pop knode from kqueue 0x%p",[m
                  pQueue);[m
 [m
[36m@@ -508,7 +535,7 @@[m [mkqueue_node_t* kQueuePop(kqueue_t* pQueue)[m
     pNode = pQueue->pTail;[m
 [m
     KERNEL_DEBUG(KQUEUE_DEBUG_ENABLED,[m
[31m-                 "KQUEUE",[m
[32m+[m[32m                 MODULE_NAME,[m
                  "Pop knode 0x%p from kqueue 0x%p",[m
                  pNode,[m
                  pQueue);[m
[36m@@ -576,7 +603,7 @@[m [mkqueue_node_t* kQueueFind(kqueue_t* pQueue, const void* kpData)[m
 #endif[m
 [m
     KERNEL_DEBUG(KQUEUE_DEBUG_ENABLED,[m
[31m-                 "KQUEUE",[m
[32m+[m[32m                 MODULE_NAME,[m
                  "KQueue try find data 0x%p from kqueue 0x%p",[m
                  kpData,[m
                  pQueue);[m
[36m@@ -595,7 +622,7 @@[m [mkqueue_node_t* kQueueFind(kqueue_t* pQueue, const void* kpData)[m
     }[m
 [m
     KERNEL_DEBUG(KQUEUE_DEBUG_ENABLED,[m
[31m-                 "KQUEUE",[m
[32m+[m[32m                 MODULE_NAME,[m
                  "KQueue found node 0x%p from kqueue 0x%p",[m
                  pNode,[m
                  pQueue);[m
[36m@@ -650,7 +677,7 @@[m [mvoid kQueueRemove(kqueue_t* pQueue, kqueue_node_t* pNode, const bool_t kPanic)[m
 #endif[m
 [m
     KERNEL_DEBUG(KQUEUE_DEBUG_ENABLED,[m
[31m-                 "KQUEUE",[m
[32m+[m[32m                 MODULE_NAME,[m
                  "KQueue try renove knode 0x%p from kqueue 0x%p",[m
                  pNode,[m
                  pQueue);[m
[36m@@ -727,7 +754,7 @@[m [mvoid kQueueRemove(kqueue_t* pQueue, kqueue_node_t* pNode, const bool_t kPanic)[m
     KERNEL_CRITICAL_UNLOCK(pQueue->lock);[m
 [m
     KERNEL_DEBUG(KQUEUE_DEBUG_ENABLED,[m
[31m-                 "KQUEUE",[m
[32m+[m[32m                 MODULE_NAME,[m
                  "KQueue renoved knode 0x%p from kqueue 0x%p",[m
                  pNode, pQueue);[m
 [m
[1mdiff --git a/Source/Kernel/core/src/scheduler.c b/Source/Kernel/core/src/scheduler.c[m
[1mindex a89c1ac..03c8405 100644[m
[1m--- a/Source/Kernel/core/src/scheduler.c[m
[1m+++ b/Source/Kernel/core/src/scheduler.c[m
[36m@@ -122,7 +122,7 @@[m [mtypedef struct[m
 #define SCHED_ASSERT(COND, MSG, ERROR) {                    \[m
     if((COND) == FALSE)                                     \[m
     {                                                       \[m
[31m-        PANIC(ERROR, "SCHED", MSG, TRUE);                   \[m
[32m+[m[32m        PANIC(ERROR, MODULE_NAME, MSG, TRUE);               \[m[41m[m
     }                                                       \[m
 }[m
 [m
[36m@@ -343,7 +343,7 @@[m [mstatic void _threadExitPoint(const THREAD_TERMINATE_CAUSE_E kCause,[m
                        kCause,[m
                        kRetState);[m
 [m
[31m-    ENTER_CRITICAL(intState);[m
[32m+[m[32m    KERNEL_ENTER_CRITICAL_LOCAL(intState);[m[41m[m
 [m
     cpuId      = cpuGetId();[m
     pCurThread = pCurrentThreadsPtr[cpuId];[m
[36m@@ -382,15 +382,13 @@[m [mstatic void _threadExitPoint(const THREAD_TERMINATE_CAUSE_E kCause,[m
         {[m
             /* Release the joining thread */[m
             pJoiningThread->state = THREAD_STATE_READY;[m
[31m-            releaseThread(pJoiningThread);[m
[32m+[m[32m            schedReleaseThread(pJoiningThread);[m[41m[m
         }[m
         KERNEL_CRITICAL_UNLOCK(pCurThread->pJoiningThread->lock);[m
     }[m
 [m
     KERNEL_CRITICAL_UNLOCK(pCurThread->lock);[m
 [m
[31m-    EXIT_CRITICAL(intState);[m
[31m-[m
     KERNEL_TRACE_EVENT(TRACE_SCHEDULER_ENABLED,[m
                        TRACE_SHEDULER_THREAD_EXIT_PT_EXIT,[m
                        3,[m
[36m@@ -401,12 +399,14 @@[m [mstatic void _threadExitPoint(const THREAD_TERMINATE_CAUSE_E kCause,[m
     /* Schedule thread, no need for interrupt, the context does not need to be[m
      * saved.[m
      */[m
[31m-    schedSchedule();[m
[32m+[m[32m    schedScheduleNoInt();[m[41m[m
 [m
     /* We should never return */[m
     SCHED_ASSERT(FALSE,[m
                  "Thread retuned after exiting",[m
                  OS_ERR_UNAUTHORIZED_ACTION);[m
[32m+[m[41m[m
[32m+[m[32m    KERNEL_EXIT_CRITICAL_LOCAL(intState);[m[41m[m
 }[m
 [m
 [m
[36m@@ -497,10 +497,10 @@[m [mstatic kernel_thread_t* _getNextThreadFromTable(thread_table_t* pTable)[m
         /* Get a thread from the list */[m
         --pTable->threadCount;[m
         pThreadNode = kQueuePop(pTable->pReadyList[nextPrio]);[m
[31m-        SCHED_ASSERT(pThreadNode != NULL,[m
[31m-                     "Got a NULL thread node",[m
[31m-                     OS_ERR_NULL_POINTER);[m
     }[m
[32m+[m[32m    SCHED_ASSERT(pThreadNode != NULL,[m[41m[m
[32m+[m[32m                 "Got a NULL thread node",[m[41m[m
[32m+[m[32m                 OS_ERR_NULL_POINTER);[m[41m[m
 [m
     /* Decrease the global highest priority if needed */[m
     for(i = nextPrio; i < KERNEL_NONE_PRIORITY; ++i)[m
[36m@@ -511,11 +511,6 @@[m [mstatic kernel_thread_t* _getNextThreadFromTable(thread_table_t* pTable)[m
             break;[m
         }[m
     }[m
[31m-[m
[31m-    SCHED_ASSERT(pThreadNode != NULL,[m
[31m-                 "Got a NULL thread node",[m
[31m-                 OS_ERR_NULL_POINTER);[m
[31m-[m
     pTable->highestPriority = i;[m
 [m
     KERNEL_CRITICAL_UNLOCK(pTable->lock);[m
[36m@@ -564,7 +559,7 @@[m [mstatic void _updateSleepingThreads(void)[m
                          OS_ERR_NULL_POINTER);[m
 [m
             /* Release the thread */[m
[31m-            releaseThread(pThreadNode->pData);[m
[32m+[m[32m            schedReleaseThread(pThreadNode->pData);[m[41m[m
         }[m
     }[m
     KERNEL_CRITICAL_UNLOCK(sSleepingThreadsTable.lock);[m
[36m@@ -681,9 +676,11 @@[m [mvoid schedInit(void)[m
     KERNEL_TRACE_EVENT(TRACE_SCHEDULER_ENABLED,[m
                        TRACE_SHEDULER_INIT_EXIT,[m
                        0);[m
[32m+[m[41m[m
[32m+[m[32m    TEST_POINT_FUNCTION_CALL(schedulerTest, TEST_SCHEDULER_ENABLED);[m[41m[m
 }[m
 [m
[31m-void schedSchedule(void)[m
[32m+[m[32mvoid schedScheduleNoInt(void)[m[41m[m
 {[m
     uint8_t          cpuId;[m
     uint8_t          currPrio;[m
[36m@@ -696,6 +693,10 @@[m [mvoid schedSchedule(void)[m
                        1,[m
                        pCurrentThreadsPtr[cpuGetId()]->tid);[m
 [m
[32m+[m[32m    SCHED_ASSERT(cpuGeIntState() == 0,[m[41m[m
[32m+[m[32m                 "Called scheduler no int with interrupt enabled",[m[41m[m
[32m+[m[32m                 OS_ERR_UNAUTHORIZED_ACTION);[m[41m[m
[32m+[m[41m[m
     /* Get current CPU ID */[m
     cpuId = cpuGetId();[m
     pCurrentTable = &sThreadTables[cpuId];[m
[36m@@ -725,7 +726,7 @@[m [mvoid schedSchedule(void)[m
              * it is currently equal or higher.[m
              */[m
             KERNEL_CRITICAL_UNLOCK(sThreadTables[cpuId].lock);[m
[31m-            releaseThread(pThread);[m
[32m+[m[32m            schedReleaseThread(pThread);[m[41m[m
 [m
             /* Elect the new thread*/[m
             pCurrentThreadsPtr[cpuId] = _getNextThreadFromTable(pCurrentTable);[m
[36m@@ -782,25 +783,34 @@[m [mvoid schedSchedule(void)[m
                  OS_ERR_UNAUTHORIZED_ACTION);[m
 }[m
 [m
[32m+[m[32mvoid schedSchedule(void)[m[41m[m
[32m+[m[32m{[m[41m[m
[32m+[m[32m    /* Just generate a scheduler interrupt */[m[41m[m
[32m+[m[32m    cpuRaiseInterrupt(sSchedulerInterruptLine);[m[41m[m
[32m+[m[32m}[m[41m[m
[32m+[m[41m[m
 void schedScheduleHandler(kernel_thread_t* pThread)[m
 {[m
     (void)pThread;[m
 [m
     /* Just call the scheduler */[m
[31m-    schedSchedule();[m
[32m+[m[32m    schedScheduleNoInt();[m[41m[m
 }[m
 [m
[31m-void releaseThread(kernel_thread_t* pThread)[m
[32m+[m[32mvoid schedReleaseThread(kernel_thread_t* pThread)[m[41m[m
 {[m
     uint64_t i;[m
     uint8_t  cpuId;[m
     double   lastCpuLoad;[m
[32m+[m[32m    uint32_t intState;[m[41m[m
 [m
     KERNEL_TRACE_EVENT(TRACE_SCHEDULER_ENABLED,[m
                        TRACE_SHEDULER_RELEASE_THREAD_ENTRY,[m
                        1,[m
                        pThread->tid);[m
 [m
[32m+[m[32m    KERNEL_ENTER_CRITICAL_LOCAL(intState);[m[41m[m
[32m+[m[41m[m
     /* Get the CPU list to release to */[m
     lastCpuLoad = 1000.0;[m
     cpuId       = MAX_CPU_COUNT;[m
[36m@@ -842,9 +852,9 @@[m [mvoid releaseThread(kernel_thread_t* pThread)[m
 [m
     kQueuePush(pThread->pThreadNode,[m
                sThreadTables[cpuId].pReadyList[pThread->priority]);[m
[32m+[m[32m    ++sThreadTables[cpuId].threadCount;[m[41m[m
     if(sThreadTables[cpuId].highestPriority > pThread->priority)[m
     {[m
[31m-        ++sThreadTables[cpuId].threadCount;[m
         sThreadTables[cpuId].highestPriority = pThread->priority;[m
     }[m
 [m
[36m@@ -861,6 +871,8 @@[m [mvoid releaseThread(kernel_thread_t* pThread)[m
                        2,[m
                        pThread->tid,[m
                        cpuId);[m
[32m+[m[41m[m
[32m+[m[32m    KERNEL_EXIT_CRITICAL_LOCAL(intState);[m[41m[m
 }[m
 [m